{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Astroinformatica II (Semester 2 2024)**\n",
    "\n",
    "# Tutorial Session 3: Parallelization\n",
    "\n",
    "*N. Hernitschek, 2022*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Contents\n",
    "* [Parallelization with Multiprocessing](#first-bullet)\n",
    "* [Avoiding slow program/ data structures](#second-bullet)\n",
    "* [Parallelization with Multithreading](#third-bullet)\n",
    "* [Summary](#fourth-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parallelization with Multiprocessing<a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "When processing large data sets, parallelization is usually possible and thus recommended. In most cases, such code runs on a large number of data independently from each other.\n",
    "e.g.: classifying objects by their light curves, calculating features for objects, estimating the distances..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multiprocessing` is a package that supports spawning processes using an API similar to the threading module. It runs on both Unix (including Mac) and Windows.\n",
    "\n",
    "More on this: https://docs.python.org/3/library/multiprocessing.html\n",
    "\n",
    "\n",
    "\n",
    "**Example:** a template to process multiple light curves in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res lightcurve_1.lc\n",
      "res lightcurve_2.lc\n",
      "res lightcurve_3.lc\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# demo code for processing one light curve\n",
    "def one_lc(param):\n",
    "\n",
    "    i, filename = param\n",
    "    \n",
    "    # here goes the code processing something, i.e.: open the file, carry out computations on light curve data\n",
    "    \n",
    "    return filename\n",
    "\n",
    "pool = Pool(processes=9)\n",
    "\n",
    "#a list of light curve files\n",
    "filenames = ['lightcurve_1.lc','lightcurve_2.lc','lightcurve_3.lc']\n",
    "\n",
    "params = [(i, filename) for i, filename in enumerate(filenames)]\n",
    "\n",
    "it = pool.imap_unordered(one_lc, params)\n",
    "\n",
    "\n",
    "for i, res in enumerate(it):\n",
    "\n",
    "    print('res', res)\n",
    "\n",
    "\n",
    "pool.terminate()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution**: Some large **clusters/ supercomputers** prefer to have parallelization implemented in a different way. E.g.: Some clusters have *quotas* on the memory usage, CPU usage, and the runtime of your code within one thread/ process, so it can make sense to rather split up your code in multiple **jobs** instead of using Python's parallelization. When using a cluster/ supercomputer, you will find this in the system's documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parallelization with Multithreading<a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "Python provides a module that enables the construction and administration\n",
    "of threads, thus making multithreaded applications easier to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "Thread task executed\n",
      "False\n",
      "False\n",
      "Thread execution completed\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def task():\n",
    "    print(thread.is_alive())\n",
    "    print(\"Thread task executed\")\n",
    "    \n",
    "# Create a thread\n",
    "thread = threading.Thread(target=task)\n",
    "print(thread.is_alive())\n",
    "# Start the thread\n",
    "thread.start()\n",
    "print(thread.is_alive())\n",
    "# Wait for the thread to complete\n",
    "thread.join()\n",
    "print(thread.is_alive())\n",
    "print(\"Thread execution completed\")\n",
    "\n",
    "print(thread.is_alive())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread Synchronization\n",
    "\n",
    "Programming for many threads requires careful consideration of thread synchronization. Preventing conflicts and race conditions entails coordinating the execution of several threads and ensuring that shared resources are accessed and modified securely. Threads can interfere with one another without adequate synchronization, resulting in data corruption, inconsistent results, or unexpected behavior.\n",
    "\n",
    "Thread synchronization is necessary when multiple threads access shared resources or variables simultaneously. The primary goals of synchronization are:\n",
    "\n",
    "#### Mutual Exclusion\n",
    "\n",
    "Ensuring that only one thread can access a shared resource or a critical code section at a time. This prevents data corruption or inconsistent states caused by concurrent modifications.\n",
    "\n",
    "\n",
    "#### Coordination\n",
    "\n",
    "Allowing threads to communicate and coordinate their activities effectively. This includes tasks like signaling other threads when a condition is met or waiting for a certain condition to be satisfied before proceeding.\n",
    "Synchronization Techniques\n",
    "\n",
    "\n",
    "Python provides various synchronization mechanisms to address thread synchronization needs. Some commonly used techniques include locks (mutexes), semaphores, and condition variables.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locks\n",
    "\n",
    "A lock, usually called a **mutex**, is a fundamental primitive for synchronization that permits mutual exclusion. While other threads wait for the lock to be released, it ensures that only one thread can ever acquire the lock. For this function, the Python threading library offers a Lock class.\n",
    "\n",
    "\n",
    "In this example, a shared counter variable is incremented by multiple threads. The Lock object, `counter_lock`, ensures mutual exclusion while accessing and modifying the counter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 10\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "counter = 0\n",
    "counter_lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    with counter_lock:\n",
    "        counter += 1\n",
    "\n",
    "# Create multiple threads to increment the counter\n",
    "threads = []\n",
    "for _ in range(10):\n",
    "    t = threading.Thread(target=increment)\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(\"Counter:\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semaphores\n",
    "\n",
    "A semaphore is a synchronization object that maintains a count. It allows multiple threads to enter a critical section up to a specified limit. If the limit is reached, subsequent threads will be blocked until a thread releases the semaphore. The `threading` module provides a `Semaphore` class for this purpose.\n",
    "\n",
    "In this example, a semaphore with a limit of 3 controls access to a shared resource. Only three threads can enter the critical section at a time, while others wait for the semaphore to be released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource: ['Thread-1', 'Thread-2', 'Thread-3', 'Thread-4', 'Thread-5', 'Thread-6', 'Thread-7', 'Thread-8', 'Thread-9', 'Thread-10']\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "semaphore = threading.Semaphore(3)  # Allow 3 threads at a time\n",
    "resource = []\n",
    "\n",
    "def access_resource():\n",
    "    with semaphore:\n",
    "        resource.append(threading.current_thread().name)\n",
    "        \n",
    "# Create multiple threads to access the resource\n",
    "threads = []\n",
    "\n",
    "for i in range(10):\n",
    "    t = threading.Thread(target=access_resource, name=f\"Thread-{i+1}\")\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    \n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    \n",
    "print(\"Resource:\", resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition Variables\n",
    "\n",
    "Condition variables allow threads to wait for a specific condition to be met before proceeding. They provide a mechanism for threads to signal each other and coordinate their activities. The `threading` module provides a `Condition` class for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "buffer = []\n",
    "buffer_size = 5\n",
    "buffer_lock = threading.Lock()\n",
    "buffer_not_full = threading.Condition(lock=buffer_lock)\n",
    "buffer_not_empty = threading.Condition(lock=buffer_lock)\n",
    "\n",
    "def produce_item(item):\n",
    "    with buffer_not_full:\n",
    "        while len(buffer) >= buffer_size:\n",
    "            buffer_not_full.wait()\n",
    "        buffer.append(item)\n",
    "        buffer_not_empty.notify()\n",
    "        \n",
    "def consume_item():\n",
    "    with buffer_not_empty:\n",
    "        while len(buffer) == 0:\n",
    "            buffer_not_empty.wait()\n",
    "        item = buffer.pop(0)\n",
    "        buffer_not_full.notify()\n",
    "        return item\n",
    "    \n",
    "# Create producer and consumer threads\n",
    "producer = threading.Thread(target=produce_item, args=(\"Item 1\",))\n",
    "consumer = threading.Thread(target=consume_item)\n",
    "producer.start()\n",
    "consumer.start()\n",
    "producer.join()\n",
    "consumer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concurrency vs. Parallelism<a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "The following example shows the principle of **concurrency**:\n",
    "\n",
    "\n",
    "We create five threads and assign each to execute the task function with a different name. Concurrency is enabled via multithreading by enabling numerous threads within a single process.\n",
    "\n",
    "You'll observe that the tasks start and complete in an interleaved manner, indicating concurrent execution.\n",
    "\n",
    "In this example, a producer thread produces items and adds them to a shared buffer, while a consumer thread consumes items from the buffer. The condition variables `buffer_not_full` and `buffer_not_empty` synchronize the producer and consumer threads, ensuring that the buffer is not full before producing and not empty before consuming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 started\n",
      "Task 1 started\n",
      "Task 2 started\n",
      "Task 3 started\n",
      "Task 4 started\n",
      "Task 0 completed\n",
      "Task 1 completed\n",
      "Task 2 completed\n",
      "Task 3 completed\n",
      "Task 4 completed\n",
      "All tasks completed\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def task(name):\n",
    "    print(f\"Task {name} started\")\n",
    "    time.sleep(2)  # Simulating some time-consuming task\n",
    "    print(f\"Task {name} completed\")\n",
    "    \n",
    "# Creating multiple threads\n",
    "threads = []\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=task, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    \n",
    "# Waiting for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    \n",
    "print(\"All tasks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows **parallelism with multiprocessing**:\n",
    "\n",
    "\n",
    "In this example, we define the same task function as before. However, instead of creating threads, we make five processes using multiprocessing. Process class. Each process is assigned to execute the task function with a different name. The processes are started and then joined to wait for their completion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 started\n",
      "Task 1 started\n",
      "Task 2 started\n",
      "Task 3 startedTask 4 started\n",
      "\n",
      "Task 0 completed\n",
      "Task 1 completed\n",
      "Task 3 completedTask 4 completed\n",
      "\n",
      "Task 2 completed\n",
      "All tasks completed\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def task(name):\n",
    "    print(f\"Task {name} started\")\n",
    "    time.sleep(2)  # Simulating some time-consuming task\n",
    "    print(f\"Task {name} completed\")\n",
    "\n",
    "# Creating multiple processes\n",
    "processes = []\n",
    "\n",
    "for i in range(5):\n",
    "    p = multiprocessing.Process(target=task, args=(i,))\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "# Waiting for all processes to complete\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print(\"All tasks completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run this code, you see that the tasks are executed in parallel.\n",
    "Each process runs independently, utilizing separate CPU cores. As a result,\n",
    "the tasks may be completed in any order, and youll observe a significant\n",
    "reduction in the execution time compared to the multithreading example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "\n",
    "In this lession, we have seen how we can improve the performance of our programs using multiprocessing and multithreading.\n",
    "\n",
    "\n",
    "Some of the **key-take-away points** are as follows:\n",
    "\n",
    "1. Multithreading allows concurrent execution of multiple threads within a single process, improving responsiveness and enabling parallelism.\n",
    "\n",
    "2. Understanding the Global Interpreter Lock (GIL) in Python is crucial when working with multithreading, as it restricts true parallelism for CPU-bound tasks.\n",
    "\n",
    "3. Synchronization mechanisms like locks, semaphores, and condition variables ensure thread safety and avoid race conditions in multithreaded programs.\n",
    "\n",
    "4. Multithreading is well-suited for I/O-bound tasks, where it can overlap I/O operations and maintain program responsiveness.\n",
    "\n",
    "5. Debugging and troubleshooting multithreaded code requires careful consideration of synchronization issues, proper error handling, and utilizing logging and debugging tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
